# <h1 align="center">âš¡ï¸BytevalKit_LLM: ä¸€ç«™å¼ LLM è¯„æµ‹å·¥å…·</h1>

<p align="center">
    <a href="https://github.com/BytevalKit/BytevalKit_LLM">
        <img alt="Build" src="https://img.shields.io/badge/BytevalKit_LLM-ğŸš€-blue">
    </a>
    <a href="https://github.com/BytevalKit/BytevalKit_LLM">
        <img alt="Build" src="https://img.shields.io/badge/è´¡çŒ®-æ¬¢è¿-blue">
    </a>
    <a href="https://github.com/BytevalKit/BytevalKit_LLM/blob/master/LICENSE">
        <img alt="License" src="https://img.shields.io/badge/è®¸å¯è¯-Apache%202.0-green">
    </a>
    <a href="https://github.com/BytevalKit/BytevalKit_LLM/releases">
        <img alt="Build" src="https://img.shields.io/badge/BytevalKit_LLM-1.0.0-red">
    </a>
</p>

<h4 align="center">
    <p>
        <a href="#æ¦‚è¿°">æ¦‚è¿°</a> |
        <a href="#æ ¸å¿ƒç‰¹æ€§">æ ¸å¿ƒç‰¹æ€§</a> |
        <a href="#å®‰è£…">å®‰è£…</a> |
        <a href="#å¿«é€Ÿå¼€å§‹">å¿«é€Ÿå¼€å§‹</a> |
        <a href="#é…ç½®è¯´æ˜">é…ç½®è¯´æ˜</a> |
        <a href="#ç³»ç»Ÿæ¶æ„">ç³»ç»Ÿæ¶æ„</a> |
        <a href="#benchmark">è¯„æµ‹ç»“æœ</a> |
        <a href="#è´¡çŒ®æŒ‡å—">è´¡çŒ®æŒ‡å—</a> |
        <a href="#è®¸å¯è¯">è®¸å¯è¯</a>
    <p>
</h4>

[English](ReadMe.md) | [ä¸­æ–‡](README_zh_CN.md)

## æ¦‚è¿°

BytevalKit_LLM æ˜¯ä¸€ä¸ªä¸“ä¸ºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ€§èƒ½è€Œè®¾è®¡çš„ç»¼åˆè¯„æµ‹æ¡†æ¶ã€‚å®ƒé€šè¿‡å£°æ˜å¼ YAML é…ç½®å®ç°è¯„æµ‹ä»»åŠ¡çš„å…¨æµç¨‹å®šåˆ¶åŒ–ï¼Œæ”¯æŒå¤šç§æ¨¡å‹éƒ¨ç½²æ–¹å¼ï¼ˆAPIã€Transformerã€vLLMï¼‰ï¼Œå¹¶æä¾›å®Œæ•´çš„"æ¨ç†-è¯„åˆ¤-è¯„åˆ†"è‡ªåŠ¨åŒ–å·¥ä½œæµã€‚

æœ¬æ¡†æ¶é‡‡ç”¨"é…ç½®å³ä»£ç "ï¼ˆConfiguration-as-Codeï¼‰çš„è®¾è®¡ç†å¿µï¼Œå°†æ¨¡å‹æ¶æ„ã€æ¨ç†é€»è¾‘ã€è¯„ä¼°æ–¹æ³•ã€æŒ‡æ ‡è®¡ç®—ç­‰å…³é”®ç¯èŠ‚æŠ½è±¡ä¸ºå¯é…ç½®é¡¹ï¼Œä½¿å®šåˆ¶åŒ–çš„è¯„æµ‹ä»»åŠ¡èƒ½å¤Ÿé€šè¿‡ä¿®æ”¹ YAML é…ç½®æ–‡ä»¶å®ç°ï¼Œè€Œéé‡å¤çš„ä»£ç å¼€å‘ã€‚

## æ ¸å¿ƒç‰¹æ€§

### ğŸš€ å¤šæ¨¡å¼æ”¯æŒ
- **API æ¨¡å¼**ï¼šæ”¯æŒOpenAI æ¥å£çš„ LLM æœåŠ¡è°ƒç”¨
- **æœ¬åœ°æ¨ç†**ï¼šæ”¯æŒåŸºäº Transformer æ¶æ„çš„æ¨¡å‹åŠ è½½ä¸æ¨ç†
- **vLLM åŠ é€Ÿ**ï¼šé›†æˆ vLLM é«˜æ€§èƒ½æ¨ç†å¼•æ“
- **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒæ‰¹é‡æ¨ç†å’Œå¹¶å‘è¯„æµ‹

### ğŸ¯ çµæ´»çš„è¯„æµ‹æ–¹å¼
- **è§„åˆ™è¯„åˆ¤**ï¼šæ”¯æŒè‡ªå®šä¹‰è§„åˆ™è¿›è¡Œç»“æœè¯„åˆ¤
- **LLM-as-Judge**ï¼šæ”¯æŒä½¿ç”¨ LLM ä½œä¸ºè¯„åˆ¤å™¨
- **CoT è¯„æµ‹**ï¼šæ”¯æŒæ€ç»´é“¾ï¼ˆChain-of-Thoughtï¼‰æ¨ç†è¿‡ç¨‹è¯„ä¼°
- **å¤šç»´åº¦è¯„ä¼°**ï¼šæ”¯æŒå¤šä¸ªç»´åº¦ç»¼åˆè¯„æµ‹ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒç”¨æˆ·è¿‡æ»¤æ‰ä¸éœ€è¦çš„ç»´åº¦

### ğŸ“Š æ•°æ®æ ¼å¼æ”¯æŒ
- JSON / JSONL æ ¼å¼
- CSV æ ¼å¼
- ç”¨æˆ·å¯ä»¥æ ¹æ®demo/dataset/ç›®å½•ä¸‹çš„ç¤ºä¾‹æ•°æ®è‡ªè¡Œå®ç°æ•°æ®é¢„å¤„ç†


### âš¡ é«˜æ•ˆæ‰§è¡Œ
- GPU èµ„æºæ™ºèƒ½åˆ†é…
- å¤šä»»åŠ¡å¹¶è¡Œæ‰§è¡Œ


## å®‰è£…

### ç¯å¢ƒè¦æ±‚
- Python 3.9+
- CUDA 11.8+ï¼ˆä½¿ç”¨ GPU æ¨ç†æ—¶éœ€è¦ï¼‰

### å®‰è£…æ­¥éª¤

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/BytevalKit/BytevalKit_LLM.git
cd BytevalKit_LLM

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

## å¿«é€Ÿå¼€å§‹

### åŸºç¡€ç”¨æ³•

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è¿è¡Œè¯„æµ‹
python3 main.py --yaml_path demo/demo.yaml

# è¿è¡Œ csvçš„æ•°æ®é›†è¯„æµ‹å‚è€ƒ
python3 main.py --yaml_path demo/cmmlu.yaml

# è¿è¡Œå¤šä»»åŠ¡è¯„æµ‹
python3 main.py --yaml_path demo/multi_task_gpu_invocation.yaml
```

### ç¤ºä¾‹é…ç½®

æˆ‘ä»¬åœ¨ `demo/` ç›®å½•ä¸‹æä¾›äº†å¤šä¸ªç¤ºä¾‹é…ç½®ï¼š
- `demo/Qwen2.5-1.5B-Instruct.yaml` - æœ¬åœ°æ¨¡å‹æ¨ç†ç¤ºä¾‹
- `demo/cot_model_eval.yaml` - CoT æ€ç»´é“¾è¯„æµ‹ç¤ºä¾‹
- `demo/single_model_vllm_inference_eval.yaml` - vLLM æ¨ç†ç¤ºä¾‹
- `demo/multi_task_gpu_invocation.yaml` - å¤šä»»åŠ¡å¹¶è¡Œç¤ºä¾‹

## é…ç½®è¯´æ˜

### YAML é…ç½®ç»“æ„

é…ç½®æ–‡ä»¶åŒ…å«ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ï¼š

#### 1. DEFAULT - ä»»åŠ¡é…ç½®
```yaml
DEFAULT:
  work_dir: /path/to/output        # è¾“å‡ºç›®å½•
  task_name: my_eval_task          # ä»»åŠ¡åç§°
  need_judge: true                 # æ˜¯å¦éœ€è¦è¯„åˆ¤
  need_calculate: true             # æ˜¯å¦è®¡ç®—æœ€ç»ˆå¾—åˆ†
  need_cot_judge: true            # æ˜¯å¦è¯„æµ‹ CoT æ€ç»´é“¾
  use_vllm: true                  # æ˜¯å¦ä½¿ç”¨ vLLM
  batch_size: 10                  # æ‰¹é‡å¤§å°
  judge_workers: 10               # è¯„åˆ¤å¹¶å‘æ•°
  vllm_cfg:
    max_seq_len: 16384
    max_out_len: 2048
```

#### 2. DATASET - æ•°æ®é›†é…ç½®
```yaml
DATASET:
  my_dataset:
    name: dataset_display_name
    path: /path/to/dataset.json
    question_key: input           # é—®é¢˜å­—æ®µåï¼ˆé»˜è®¤: inputï¼‰
    answer_key: target           # ç­”æ¡ˆå­—æ®µåï¼ˆé»˜è®¤: targetï¼‰
    judge_type: rule_comparison  # è¯„åˆ¤ç±»å‹ï¼šrule_comparison æˆ– llm_judge
    
    # è‡ªå®šä¹‰æ•°æ®é¢„å¤„ç†
    exec_code: |+
      question = item['question'] + " é€‰é¡¹: " + str(item['options'])
      answer = item['answer']
    
    # è‡ªå®šä¹‰è¯„åˆ¤è§„åˆ™ï¼ˆrule_comparison æ—¶ä½¿ç”¨ï¼‰
    judge_code: |+
      import re
      match = re.search(r'ç­”æ¡ˆæ˜¯\s*([A-D])', item.prediction)
      if match:
          judge_result = match.group(1) == item.answer
    
    # LLM è¯„åˆ¤æç¤ºè¯ï¼ˆllm_judge æ—¶ä½¿ç”¨ï¼‰
    judge_prompt: "è¯·è¯„åˆ¤ä»¥ä¸‹å›ç­”çš„è´¨é‡..."
    
    # è¯„ä¼°ç»´åº¦è¿‡æ»¤
    filter_key: ["æ¸…æ™°åº¦", "å®Œå¤‡æ€§"]  # ä»…ä¿ç•™æŒ‡å®šç»´åº¦
```
exec_codeæ‰§è¡Œä½ç½®ä¸ºï¼šprompt_format.pyä¸­get_infer_listå‡½æ•°
judge_codeçš„æ‰§è¡Œä½ç½®ä¸ºï¼šjudge.pyä¸­exact_matchå‡½æ•°
#### 3. MODEL - æ¨¡å‹é…ç½®
```yaml
MODEL:
  # API æ¨¡å‹ç¤ºä¾‹
  gpt4:
    type: api
    name: gpt-4
    api_key: ${API_KEY}
    
  # æœ¬åœ°æ¨¡å‹ç¤ºä¾‹
  qwen2_5:
    type: vllm  # æˆ–ä¸æŒ‡å®šï¼Œé»˜è®¤ä½¿ç”¨ transformers
    name: Qwen2.5-7B-Instruct
    path: /path/to/model
    model_kwargs:
      torch_dtype: bfloat16
      trust_remote_code: true
    meta_template:
      SYSTEM_begin: "<|im_start|>system\n"
      SYSTEM_end: "<|im_end|>\n"
      HUMAN_begin: "<|im_start|>user\n"
      HUMAN_end: "<|im_end|>\n"
      BOT_begin: "<|im_start|>assistant\n"
      BOT_end: "<|im_end|>\n"
```

## ç³»ç»Ÿæ¶æ„

### æ‰§è¡Œæµç¨‹

<details>
<summary>æŸ¥çœ‹æ‰§è¡Œæµç¨‹å›¾</summary>

```mermaid
sequenceDiagram
    participant é…ç½®ç³»ç»Ÿ
    participant ä»»åŠ¡è°ƒåº¦å™¨
    participant æ¨¡å‹æ¨ç†
    participant è¯„åˆ¤æœåŠ¡
    participant æŒ‡æ ‡è®¡ç®—å™¨
    
    é…ç½®ç³»ç»Ÿ->>ä»»åŠ¡è°ƒåº¦å™¨: åŠ è½½é…ç½®
    ä»»åŠ¡è°ƒåº¦å™¨->>æ¨¡å‹æ¨ç†: åˆ†é…ä»»åŠ¡
    æ¨¡å‹æ¨ç†->>è¯„åˆ¤æœåŠ¡: å‘é€æ¨ç†ç»“æœ
    è¯„åˆ¤æœåŠ¡-->>æŒ‡æ ‡è®¡ç®—å™¨: è¿”å›è¯„åˆ†
    æŒ‡æ ‡è®¡ç®—å™¨->>è¾“å‡ºç³»ç»Ÿ: ç”ŸæˆæŠ¥å‘Š
```
</details>

### æ¶æ„å›¾
<p align="center">
    <a href="assets/architecture_zh-CN.png">
        <img src="assets/architecture_zh-CN.png" width="600" alt="ç‚¹å‡»æŸ¥çœ‹å¤§å›¾" />
    </a>
</p>
<p align="center"><i>ç‚¹å‡»å›¾ç‰‡æŸ¥çœ‹å¤§å›¾</i></p>


### ç›®å½•ç»“æ„


```
BytevalKit_LLM/
â”œâ”€â”€ main.py              # ä¸»å…¥å£
â”œâ”€â”€ models/              # æ¨¡å‹æ¥å£
â”‚   â”œâ”€â”€ api_model.py     # API æ¨¡å‹æ¥å£
â”‚   â”œâ”€â”€ hf_model.py      # Huggingface æ¨¡å‹
â”‚   â””â”€â”€ vllm_model.py    # vLLM æ¨¡å‹
â”œâ”€â”€ execute/             # æ‰§è¡Œå¼•æ“
â”‚   â”œâ”€â”€ infer.py          # æ¨ç†æ¨¡å—
â”‚   â”œâ”€â”€ judge.py           # è¯„åˆ¤æ¨¡å—
â”‚   â””â”€â”€ task.py            # ä»»åŠ¡ç®¡ç†
â”œâ”€â”€ demo/                # ç¤ºä¾‹é…ç½®å’Œæ•°æ®
    â”œâ”€â”€ dataset/         # ç¤ºä¾‹æ•°æ®é›†
    â””â”€â”€ *.yaml          # ç¤ºä¾‹é…ç½®æ–‡ä»¶

```

## Benchmark

> æ³¨æ„ï¼šä¸ºäº†è¡¨æ˜æˆ‘ä»¬çš„æ¡†æ¶é€‚ç”¨äºå¼€æºæ•°æ®é›†çš„è¯„æµ‹æ–¹å¼ï¼Œæˆ‘ä»¬ä½¿ç”¨å¼€æºæ¨¡å‹åœ¨éƒ¨åˆ†è¯„æµ‹é›†è¿›è¡Œæ¡†æ¶éªŒè¯ï¼Œä½¿ç”¨çš„è¯„æµ‹é€»è¾‘å‡ä¸ºLLMè¯„æµ‹

> ä»¥ä¸‹ä»…ä¸ºæ¡†æ¶è¯„æµ‹ç»“æœï¼Œæ¨¡å‹æ— å…ˆåé¡ºåº



| Dataset | Metric | Qwen3_32B | qwen3-14b | qwen3-235b<br>-a22b | DeepSeek-V3-671B | qwen1.7B-instruct | Qwen3_8B | Qwen2.5_1.5B | Qwen2.5_7B |
|---------|--------|-----------|-----------|---------------------|------------------|-------------------|----------|--------------|------------|
| AIME24 | acc | 33.33 | 26.67 | 46.67 | 33.3 | 16.67 | 23.3 | 3.33 | 13.3 |
| AIME25 | acc | 20 | 23.33 | 27.5 | 25.83 | 7.5 | 8.33 | 0 | 15.42 |
| C-SimpleQA | acc | 40.12 | 37.21 | 54.39 | 58.79 | 13.67 | 31.85 | 12.56 | 23.43 |
| MATH-500 | acc | 75.4 | 75.8 | 87.8 | 71.6 | 71.2 | 83 | 55.8 | 77.8 |
| bbh | acc | 87.39 | 84.59 | 88.81 | 87.01 | 55 | 80.3 | 36.2 | 64.3 |
| ceval-gen | acc | 84.77 | 82.8 | 85.78 | 90 | 53.8 | 76.3 | 54.23 | 73.99 |
| cmmlu-gen | acc | 73.33 | 77.9 | 82.49 | 79.2 | 53.13 | 75.82 | 66.28 | 73.73 |
| hellaswag-gen | acc | 81.1 | 54.4 | 84.48 | 82.6 | 61 | 70.3 | 56.25 | 69.6 |
| GPQA-Diamond | acc | 54 | 54.55 | 62.63 | 48.48 | 26.77 | 40.4 | 30.3 | 34.4 |
| MMLU-Pro | acc | 72.86 | 67.14 | 78.58 | 78.57 | 41.43 | 74.3 | 32.14 | 62.85 |


### æ•°æ®é›†è¯´æ˜

æ„Ÿè°¢ä»¥ä¸‹å¼€æºæ•°æ®é›†çš„è´¡çŒ®ï¼Œæˆ‘ä»¬å·²å°†æ ¼å¼åŒ–åçš„ç‰ˆæœ¬æ”¾ç½®åœ¨ `demo/dataset/` ç›®å½•ä¸‹ï¼š
- AIME2024
- C-SimpleQA
- MATH-500
- bbh
- ceval-gen
- cmmlu-gen
- hellaswag
- GPQA-Diamond
- MMLU-Pro

## è‡ªå®šä¹‰æ‰©å±•


### è‡ªå®šä¹‰ LLM Judge
ä¿®æ”¹ `execute/judge.py`ï¼Œçš„llm_judgeå‡½æ•°å®ç°æ‚¨çš„è¯„åˆ¤é€»è¾‘ã€‚

### å¹¶å‘ä¼˜åŒ–
åœ¨è¯„åˆ¤æ¨¡å—ä¸­åŠ å…¥å¹¶å‘è¯·æ±‚èƒ½åŠ›ï¼Œå¯æ˜¾è‘—æå‡è¯„æµ‹é€Ÿåº¦ã€‚

## è´¡çŒ®

è¯¥é¡¹ç›®ç”±BytevalKitå›¢é˜Ÿå¼€å‘ï¼Œå¼€å‘æˆå‘˜ï¼š

```
{Peijie Bu, Yan Qiu, Shenwei Huang}, Yaling Mou, Xianxian Ma, 
Ming Jiang, Haizhen Liao, Jingwei Sun, Binbin Xing

{*} Equal Contributions.
```

æˆ‘ä»¬ä¹Ÿæ„Ÿè°¢æŠ–éŸ³åº”ç”¨ç®—æ³•å›¢é˜Ÿçš„æ”¯æŒï¼š

```
Xusheng Wang, Fubang Zhao, Jianhui Pang, Mingsi Ye, Jie Tang, Kang Yang, Xiaopu Wang, Shuang Zeng
Fei Jiang, Ying Ju, Chuang Fan, Chuwei Luo, Qingsong Liu, Xu Chen
Yi Lin, Junfeng Yao, Chao Feng, Jiao Ran
```

ä»¥åŠäº§å“è®¾è®¡å’ŒBytevalå¹³å°ä¾§æä¾›çš„æ”¯æŒï¼š

```
Ziyu Shi, Zhao Lin, Yang Li, Jing Yang, Zhen Wang, Guojun Ma
```

ä»¥åŠAI platformå›¢é˜Ÿçš„æˆå‘˜:

```
Huiyu Yu, Lin Dong, Yong Zhang
```

æˆ‘ä»¬æ¬¢è¿å„ç§å½¢å¼çš„è´¡çŒ®ï¼è¯·æŸ¥çœ‹æˆ‘ä»¬çš„[è´¡çŒ®æŒ‡å—](CONTRIBUTING.md)äº†è§£è¯¦æƒ…ã€‚

ç‰¹åˆ«æ„Ÿè°¢ [OpenCompass](https://github.com/open-compass/opencompass) æä¾›çš„å¼€æºæ¡†æ¶ï¼Œä¸ºæˆ‘ä»¬æä¾›äº†å®è´µçš„è®¾è®¡æ€è·¯ã€‚

## å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº† BytevalKit_LLMï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@misc{BytevalKit-LLM-2025,
  title={BytevalKit-LLM: Comprehensive LLM Evaluation Framework},
  author={BytevalKit},
  year={2025},
  howpublished={\url{https://github.com/BytevalKit/BytevalKit_LLM}}
}
```

## è®¸å¯è¯

BytevalKit-LLM ä½¿ç”¨ [Apache License 2.0](LICENSE) è®¸å¯è¯ã€‚

## è”ç³»æˆ‘ä»¬

å¦‚æœ‰ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿è”ç³»æˆ‘ä»¬ï¼šBytevalKit@bytedance.com